import os
import sqlite3
import json
import asyncio
import aiosqlite
import shutil
import re
from cachetools import TTLCache
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register, StarTools
from astrbot.api import logger
from astrbot.api.message_components import *

@register("astrbot_plugin_webnovel_bible", "Foolllll", "é›†æˆäº†æ‰«ä¹¦å®å…¸ï¼Œæ”¯æŒæŸ¥è¯¢ä¹¦å/ä½œè€…è·å–å°è¯´çš„æ‰«ä¹¦è®°å½•ä»¥åŠç›¸å…³æœ¯è¯­æŸ¥è¯¢ã€‚", "1.0", "https://github.com/Foolllll-J/astrbot_plugin_webnovel_bible")
class WebnovelBiblePlugin(Star):
    def __init__(self, context: Context, config: dict = None):
        super().__init__(context)
        self.config = config or {}
        self.group_whitelist = self.config.get("group_whitelist", [])
        self.max_records_per_book = self.config.get("max_records_per_book", 20)
        self.max_review_length = self.config.get("max_review_length", 4000)
        self.max_batch_chars = self.config.get("max_batch_chars", 5000)
        
        # è·¯å¾„è®¾ç½®
        self.data_dir = StarTools.get_data_dir("astrbot_plugin_webnovel_bible")
        os.makedirs(self.data_dir, exist_ok=True)
        self.db_path = os.path.join(self.data_dir, "webnovel.db")
        
        # èµ„æºè·¯å¾„
        self.plugin_dir = os.path.dirname(__file__)
        self.resource_db_path = os.path.join(self.plugin_dir, "resources", "webnovel.db")
        
        # æœ¯è¯­èµ„æºåŠ è½½
        self.categories = {
            "é˜²å¾¡": "defenses.json",
            "éƒé—·": "depressions.json",
            "é›·ç‚¹": "mines.json",
            "æœ¯è¯­": "terms.json"
        }
        self.terms_data = {cat: {} for cat in self.categories}
        self.tag_emojis = {}
        self.search_states = TTLCache(maxsize=1000, ttl=600)
        self._initialized = False
        self._init_lock = asyncio.Lock()
        
        self._load_terminology()
        self._load_tag_emojis()

    def _load_tag_emojis(self):
        emoji_path = os.path.join(os.path.dirname(__file__), "resources", "tag_emoji.json")
        if os.path.exists(emoji_path):
            try:
                with open(emoji_path, "r", encoding="utf-8") as f:
                    self.tag_emojis = json.load(f)
                logger.info(f"æˆåŠŸåŠ è½½ {len(self.tag_emojis)} ä¸ªæ ‡ç­¾ Emoji æ˜ å°„ã€‚")
            except Exception as e:
                logger.error(f"åŠ è½½ tag_emoji.json å¤±è´¥: {e}")
        else:
            logger.warning("æœªæ‰¾åˆ° tag_emoji.json èµ„æºæ–‡ä»¶ã€‚")

    def _load_terminology(self):
        total_loaded = 0
        for cat, filename in self.categories.items():
            file_path = os.path.join(self.plugin_dir, "resources", filename)
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        count = 0
                        for item in data:
                            name = item.get("åç§°")
                            if name:
                                self.terms_data[cat][name] = item
                                count += 1
                        self.terms_data[cat] = dict(sorted(self.terms_data[cat].items()))
                        logger.info(f"æˆåŠŸåŠ è½½{cat}åˆ†ç±»æœ¯è¯­: {count} æ¡")
                        total_loaded += count
                except Exception as e:
                    logger.error(f"åŠ è½½æœ¯è¯­æ–‡ä»¶ {filename} å¤±è´¥: {e}")
            else:
                logger.warning(f"æœ¯è¯­æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        logger.info(f"æœ¯è¯­èµ„æºåŠ è½½å®Œæˆï¼Œå…±è®¡ {total_loaded} æ¡è®°å½•ã€‚")

    async def _ensure_initialized(self):
        async with self._init_lock:
            if not self._initialized:
                if not os.path.exists(self.db_path):
                    if os.path.exists(self.resource_db_path):
                        shutil.copy(self.resource_db_path, self.db_path)
                        logger.info(f"å·²å°†æ•°æ®åº“ä»èµ„æºç›®å½•å¤åˆ¶åˆ°æ•°æ®ç›®å½•: {self.db_path}")
                    else:
                        logger.error("èµ„æºç›®å½•ä¸­æœªæ‰¾åˆ° webnovel.dbï¼Œè¯·æ£€æŸ¥æ’ä»¶å®‰è£…æ˜¯å¦å®Œæ•´ã€‚")
                self._initialized = True

    def _get_user_state(self, user_id: str):
        if user_id not in self.search_states:
            self.search_states[user_id] = {
                "results": [],
                "keyword": ""
            }
        return self.search_states[user_id]

    @filter.command("æ‰«ä¹¦")
    async def handle_saoshu(self, event: AstrMessageEvent):
        """ç½‘æ–‡æ‰«ä¹¦å®å…¸æŸ¥è¯¢
        ç”¨æ³•: 
        /æ‰«ä¹¦ <ä¹¦å/ä½œè€…> - æœç´¢ä¹¦ç±
        /æ‰«ä¹¦ <ä¹¦å/ä½œè€…> <åºå·> - æœç´¢å¹¶ç›´æ¥æŸ¥çœ‹ç¬¬ N ä¸ªç»“æœ
        /æ‰«ä¹¦ <åºå·> - æŸ¥çœ‹æœç´¢ç»“æœä¸­çš„è¯¦ç»†ä¿¡æ¯
        """
        await self._ensure_initialized()
        
        # ç¾¤ç»„ç™½åå•æ£€æŸ¥
        if self.group_whitelist:
            group_id = event.message_obj.group_id
            if group_id and group_id not in self.group_whitelist:
                return

        parts = event.message_str.strip().split()
        if len(parts) < 2:
            yield event.plain_result("è¯·è¾“å…¥ä¹¦åæˆ–ä½œè€…è¿›è¡ŒæŸ¥è¯¢ï¼Œä¾‹å¦‚: /æ‰«ä¹¦ æå“å®¶ä¸")
            return

        user_id = event.get_sender_id()
        state = self._get_user_state(user_id)
        
        # è¯†åˆ«æœ«å°¾çš„åºå·ï¼ˆå¦‚ï¼š/æ‰«ä¹¦ æå“å®¶ä¸ 1ï¼‰
        direct_idx = None
        if len(parts) > 2 and parts[-1].isdigit():
            direct_idx = int(parts[-1]) - 1
            query = " ".join(parts[1:-1])
        else:
            query = " ".join(parts[1:])
        
        logger.debug(f"ç”¨æˆ· {user_id} æ‰«ä¹¦æŸ¥è¯¢: {query}, ç›´æ¥åºå·: {direct_idx + 1 if direct_idx is not None else 'æ— '}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯çº¯åºå·ï¼ˆå¦‚ï¼š/æ‰«ä¹¦ 1ï¼‰
        if query.isdigit() and direct_idx is None:
            idx = int(query) - 1
            if state["results"] and 0 <= idx < len(state["results"]):
                novel_id = state["results"][idx]["id"]
                logger.info(f"ç”¨æˆ· {user_id} é€‰æ‹©åºå· {query}, ä¹¦ç± ID: {novel_id}")
                async for res in self.show_details(event, novel_id):
                    yield res
                return
            else:
                logger.warning(f"ç”¨æˆ· {user_id} è¾“å…¥æ— æ•ˆåºå·: {query}")

        # æ‰§è¡Œæœç´¢
        async for res in self.search_novels(event, query, state, direct_idx):
            yield res


    @filter.command("é˜²å¾¡")
    async def handle_defense(self, event: AstrMessageEvent):
        """é˜²å¾¡æœ¯è¯­æŸ¥è¯¢"""
        async for res in self._handle_category_command(event, "é˜²å¾¡"):
            yield res

    @filter.command("éƒé—·")
    async def handle_depression(self, event: AstrMessageEvent):
        """éƒé—·æœ¯è¯­æŸ¥è¯¢"""
        async for res in self._handle_category_command(event, "éƒé—·"):
            yield res

    @filter.command("é›·ç‚¹")
    async def handle_mine(self, event: AstrMessageEvent):
        """é›·ç‚¹æœ¯è¯­æŸ¥è¯¢"""
        async for res in self._handle_category_command(event, "é›·ç‚¹"):
            yield res

    @filter.command("æœ¯è¯­")
    async def handle_term(self, event: AstrMessageEvent):
        """é€šç”¨æœ¯è¯­æŸ¥è¯¢"""
        async for res in self._handle_category_command(event, "æœ¯è¯­"):
            yield res

    async def _handle_category_command(self, event: AstrMessageEvent, category: str):
        parts = event.message_str.strip().split()
        if len(parts) < 2:
            yield event.plain_result(f"è¯·è¾“å…¥è¦æŸ¥è¯¢çš„{category}æœ¯è¯­ï¼Œæˆ–è¾“å…¥ 'åˆ—è¡¨' æŸ¥çœ‹æ‰€æœ‰ã€‚")
            return

        query = " ".join(parts[1:])
        category_data = self.terms_data.get(category, {})

        if query == "åˆ—è¡¨":
            names = list(category_data.keys())
            if not names:
                yield event.plain_result(f"æš‚æ— {category}æœ¯è¯­æ•°æ®ã€‚")
                return
            resp = f"ğŸ“œ {category}åˆ—è¡¨ï¼š\n"
            resp += "ã€".join(names)
            yield event.plain_result(resp)
            return

        if query in category_data:
            item = category_data[query]
            name = item.get("åç§°")
            
            # ç»„è£…è§£é‡Š
            msg = f"ã€{category}ã€‘{name}\n"
            
            # å¦‚æœæœ‰æ–°ç‰ˆ/è€ç‰ˆè§£é‡Šï¼Œåˆ†åˆ«æ˜¾ç¤º
            has_multiple = "æ–°ç‰ˆè§£é‡Š" in item and "è€ç‰ˆè§£é‡Š" in item
            
            if "æ–°ç‰ˆè§£é‡Š" in item:
                msg += f"\n[æ–°ç‰ˆè§£é‡Š]\n{item['æ–°ç‰ˆè§£é‡Š']}\n"
            
            if "è€ç‰ˆè§£é‡Š" in item:
                msg += f"\n[è€ç‰ˆè§£é‡Š]\n{item['è€ç‰ˆè§£é‡Š']}\n"
                
            # å¦‚æœåªæœ‰å•ä¸€çš„ "è§£é‡Š"
            if "è§£é‡Š" in item and not ("æ–°ç‰ˆè§£é‡Š" in item or "è€ç‰ˆè§£é‡Š" in item):
                msg += f"\n{item['è§£é‡Š']}\n"
            
            yield event.plain_result(msg.strip())
        else:
            # å°è¯•æ¨¡ç³ŠåŒ¹é…
            matches = [t for t in category_data.keys() if query in t]
            if matches:
                if len(matches) == 1:
                    # å¦‚æœåªæœ‰ä¸€ä¸ªåŒ¹é…ï¼Œç›´æ¥æ˜¾ç¤ºè¯¦æƒ…
                    match_name = matches[0]
                    async for res in self._handle_category_command_by_name(event, category, match_name):
                        yield res
                else:
                    resp = f"æœªåœ¨{category}ä¸­æ‰¾åˆ° '{query}'ï¼Œä½ æ˜¯å¦åœ¨æ‰¾ï¼š\n"
                    resp += "ã€".join(matches[:10])
                    yield event.plain_result(resp)
            else:
                yield event.plain_result(f"æœªåœ¨{category}ä¸­æ‰¾åˆ°æœ¯è¯­ '{query}'ã€‚")

    async def _handle_category_command_by_name(self, event, category, name):
        # å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…åˆ°å”¯ä¸€ç»“æœæ—¶æ˜¾ç¤ºè¯¦æƒ…
        category_data = self.terms_data.get(category, {})
        item = category_data.get(name)
        if not item: return

        msg = f"ã€{category}ã€‘{name}\n"
        if "æ–°ç‰ˆè§£é‡Š" in item:
            msg += f"\n[æ–°ç‰ˆè§£é‡Š]\n{item['æ–°ç‰ˆè§£é‡Š']}\n"
        if "è€ç‰ˆè§£é‡Š" in item:
            msg += f"\n[è€ç‰ˆè§£é‡Š]\n{item['è€ç‰ˆè§£é‡Š']}\n"
        if "è§£é‡Š" in item and not ("æ–°ç‰ˆè§£é‡Š" in item or "è€ç‰ˆè§£é‡Š" in item):
            msg += f"\n{item['è§£é‡Š']}\n"
        yield event.plain_result(msg.strip())

    async def search_novels(self, event, query, state, direct_idx=None):
        logger.info(f"æ­£åœ¨æ•°æ®åº“ä¸­æœç´¢ä¹¦ç±: {query}")
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            # æ¨¡ç³ŠåŒ¹é…ä¹¦åã€åˆ«åæˆ–ä½œè€…
            sql = """
                SELECT id, title, author, platform, aliases 
                FROM novels 
                WHERE title LIKE ? OR author LIKE ? OR aliases LIKE ?
                LIMIT 10
            """
            search_pattern = f"%{query}%"
            async with db.execute(sql, (search_pattern, search_pattern, search_pattern)) as cursor:
                rows = await cursor.fetchall()

            if not rows:
                logger.info(f"æœªæ‰¾åˆ°ç›¸å…³ä¹¦ç±: {query}")
                yield event.plain_result(f"æœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„ä¹¦ç±ã€‚")
                return

            logger.info(f"æœç´¢åˆ° {len(rows)} æœ¬ä¹¦ç±ã€‚")
            
            # æ›´æ–°çŠ¶æ€ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨åºå·æŸ¥è¯¢
            state["results"] = [{"id": r["id"], "title": r["title"]} for r in rows]
            state["keyword"] = query

            if direct_idx is not None:
                if 0 <= direct_idx < len(rows):
                    logger.info(f"ç›´æ¥è·³è½¬åˆ°æœç´¢ç»“æœçš„ç¬¬ {direct_idx + 1} é¡¹: {rows[direct_idx]['title']}")
                    async for res in self.show_details(event, rows[direct_idx]["id"]):
                        yield res
                    return
                else:
                    logger.warning(f"ç›´æ¥è·³è½¬åºå· {direct_idx + 1} è¶…å‡ºæœç´¢ç»“æœèŒƒå›´ (å…± {len(rows)} é¡¹)")
                    # å¦‚æœåºå·è¶…å‡ºèŒƒå›´ï¼Œåˆ™å›é€€åˆ°æ˜¾ç¤ºåˆ—è¡¨

            if len(rows) == 1:
                # åªæœ‰ä¸€ä¸ªç»“æœï¼Œç›´æ¥æ˜¾ç¤ºæ‰«ä¹¦è®°å½•
                async for res in self.show_details(event, rows[0]["id"]):
                    yield res
            else:
                # å¤šä¸ªç»“æœï¼Œæ˜¾ç¤ºåˆ—è¡¨
                resp = f"æ‰¾åˆ°ä»¥ä¸‹ä¸ '{query}' ç›¸å…³çš„ä¹¦ç±ï¼š\n"
                for i, row in enumerate(rows, 1):
                    author = row["author"] or "æœªçŸ¥"
                    resp += f"{i}. ã€Š{row['title']}ã€‹ - {author}\n"
                resp += "\nè¯·è¾“å…¥ '/æ‰«ä¹¦ <åºå·>' æŸ¥çœ‹è¯¦ç»†æ‰«ä¹¦è®°å½•ã€‚"
                yield event.plain_result(resp)

    def _clean_text(self, text):
        if not text:
            return text
        # ç§»é™¤ã€ã€‘åŠå…¶å†…å®¹
        text = re.sub(r'[ã€\[].*?[ã€‘\]]', '', text)
        # ç§»é™¤æ‹¬å·åŠå…¶å†…éƒ¨å†…å®¹
        text = re.split(r'[ï¼ˆ(]', text)[0].strip()
        # ç§»é™¤æœ«å°¾çš„å­—æ•°ä¿¡æ¯ï¼ˆå¦‚ " 110wå­—", " 110ä¸‡å­—"ï¼‰
        text = re.split(r'\s+\d+(?:\.\d+)?[wWä¸‡]?(?:å­—|$)|\s+', text)[0].strip()
        return text

    async def show_details(self, event: AstrMessageEvent, novel_id):
        logger.info(f"æ­£åœ¨è·å–ä¹¦ç± ID {novel_id} çš„æ‰«ä¹¦è¯¦æƒ…...")
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            # è·å–åŸºæœ¬ä¿¡æ¯
            async with db.execute("SELECT title, author, platform FROM novels WHERE id = ?", (novel_id,)) as cursor:
                novel = await cursor.fetchone()
            
            if not novel:
                logger.error(f"æ•°æ®åº“ä¸­æ‰¾ä¸åˆ° ID ä¸º {novel_id} çš„ä¹¦ç±ä¿¡æ¯")
                yield event.plain_result("é”™è¯¯ï¼šæ‰¾ä¸åˆ°è¯¥ä¹¦ç±ä¿¡æ¯ã€‚")
                return

            # è·å–æ‰€æœ‰æ‰«ä¹¦è®°å½•
            sql = """
                SELECT r.reviewer, r.source_url, r.review_date, r.category, r.attributes
                FROM reviews r
                JOIN novel_review_map m ON r.id = m.review_id
                WHERE m.novel_id = ?
                ORDER BY r.review_date DESC
                LIMIT ?
            """
            async with db.execute(sql, (novel_id, self.max_records_per_book)) as cursor:
                reviews = await cursor.fetchall()

            logger.info(f"ä¹¦ç± ã€Š{novel['title']}ã€‹ è·å–äº† {len(reviews)} æ¡æ‰«ä¹¦è®°å½• (ä¸Šé™ {self.max_records_per_book})ã€‚")

            nodes = []
            self_id = event.get_self_id()
            bot_name = "æ‰«ä¹¦è®°å½•"

            if not reviews:
                nodes.append(Node(uin=self_id, name=bot_name, content=[Plain(text="æš‚æ— è¯¦ç»†æ‰«ä¹¦è®°å½•ã€‚")]))
                yield event.chain_result([Nodes(nodes=nodes)])
                return

            clean_title = novel['title']
            clean_author = self._clean_text(novel['author'])

            nodes = []
            batch_total_chars = 0
            batch_count = 1
            
            for i, rev in enumerate(reviews, 1):
                reviewer = self._clean_text(rev['reviewer']) or 'åŒ¿å'
                msg = f"ã€è®°å½• #{i}ã€‘ {rev['category'] or 'æ‰«ä¹¦'}\n"
                date_str = rev['review_date']
                if date_str:
                    msg += f"æ‰«ä¹¦äººï¼š{reviewer} | æ—¥æœŸï¼š{date_str}\n"
                else:
                    msg += f"æ‰«ä¹¦äººï¼š{reviewer}\n"
                
                # æ¥æºå±•ç¤º
                attrs = json.loads(rev['attributes'])
                source = rev['source_url'] or attrs.get("æ¥æº")
                if source:
                    if isinstance(source, list): source = source[0]
                    clean_source = re.split(r'[ï¼ˆ(]', str(source))[0].strip()
                    msg += f"æ¥æºï¼š{clean_source}\n"
                
                msg += "-" * 20 + "\n"

                # åŠ¨æ€å±•ç¤ºå±æ€§
                for key, value in attrs.items():
                    if not value: continue
                    # æ’é™¤å†—ä½™ä¿¡æ¯
                    if key in ["å…¶ä»–è¯´æ˜", "æ¥æº"]: continue
                    if key in ["ä¹¦å", "ä½œè€…", "å°è¯´ä½œè€…"] and (clean_title in str(value) or (clean_author and clean_author in str(value))):
                        continue
                    
                    if isinstance(value, list):
                        value = "ï¼›".join(value)
                    
                    # åŒ¹é… emoji
                    emoji = self.tag_emojis.get(key, "â—")
                    # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚â€œå¯èƒ½çš„é›·ç‚¹â€åŒ¹é…â€œé›·ç‚¹â€çš„ emojiï¼‰
                    if emoji == "â—":
                        for tag, e in self.tag_emojis.items():
                            if tag in key:
                                emoji = e
                                break
                        
                    msg += f"{emoji} {key}ï¼š{value}\n"
                
                # æ­£æ–‡æè¿° (å‚è€ƒ cli_explorer.py ä¼˜å…ˆä» attributes["å…¶ä»–è¯´æ˜"] è·å–)
                content = attrs.get("å…¶ä»–è¯´æ˜")
                if content:
                    msg += f"\n[æ­£æ–‡æè¿°]\n{str(content).strip()}"
                
                # è®¾ç½®å•ç¯‡æ‰«ä¹¦è®°å½•çš„é•¿åº¦é™åˆ¶ï¼Œé˜²æ­¢åˆå¹¶è½¬å‘å¤±è´¥ï¼ˆé€šå¸¸é™åˆ¶åœ¨ 4000 å­—ç¬¦/æ±‰å­—ä»¥å†…ï¼‰
                max_len = self.max_review_length
                final_msg = msg.strip()
                if len(final_msg) > max_len:
                    final_msg = final_msg[:max_len] + "\n\n...(å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
                    logger.warning(f"ä¹¦ç± ID {novel_id} çš„è®°å½• #{i} é•¿åº¦è¶…è¿‡ {max_len}ï¼Œå·²æˆªæ–­ã€‚")
                
                current_len = len(final_msg)
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ‰¹æ¬¡å­—ç¬¦ä¸Šé™
                if nodes and batch_total_chars + current_len > self.max_batch_chars:
                    logger.info(f"ä¹¦ç± ID {novel_id} å‘é€æ‰¹æ¬¡ {batch_count}ï¼Œå…± {len(nodes)} æ¡è®°å½•ï¼Œæ€»å­—ç¬¦æ•°: {batch_total_chars}")
                    yield event.chain_result([Nodes(nodes=nodes)])
                    nodes = []
                    batch_total_chars = 0
                    batch_count += 1
                    await asyncio.sleep(0.5)

                nodes.append(Node(uin=self_id, name=bot_name, content=[Plain(text=final_msg)]))
                batch_total_chars += current_len

            # å‘é€æœ€åä¸€æ‰¹
            if nodes:
                logger.info(f"ä¹¦ç± ID {novel_id} å‘é€æ‰¹æ¬¡ {batch_count}ï¼Œå…± {len(nodes)} æ¡è®°å½•ï¼Œæ€»å­—ç¬¦æ•°: {batch_total_chars}")
                yield event.chain_result([Nodes(nodes=nodes)])

    @filter.command("æ‰«ä¹¦ç»Ÿè®¡")
    async def handle_saoshu_stats(self, event: AstrMessageEvent):
        """æŸ¥çœ‹æ‰«ä¹¦å®å…¸ç»Ÿè®¡ä¿¡æ¯"""
        await self._ensure_initialized()
        async with aiosqlite.connect(self.db_path) as db:
            async with db.execute("SELECT COUNT(*) FROM novels") as cursor:
                novel_count = (await cursor.fetchone())[0]
            async with db.execute("SELECT COUNT(*) FROM reviews") as cursor:
                review_count = (await cursor.fetchone())[0]
        
        yield event.plain_result(f"ğŸ“Š æ‰«ä¹¦å®å…¸ç»Ÿè®¡ä¿¡æ¯ï¼š\nå…±æ”¶å½•ä½œå“ï¼š{novel_count} éƒ¨\nå…±æ”¶å½•æ‰«ä¹¦è®°å½•ï¼š{review_count} æ¡")
